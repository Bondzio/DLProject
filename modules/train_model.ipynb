{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usQ1xJayQ3AD"
   },
   "source": [
    "# Sparse Sequence-to-Sequence Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "9oJe-aJ7Qy0H",
    "outputId": "86dbab4b-bf45-4475-e240-39762a723153"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.rendered_html { font-size: 18px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "from time import time\n",
    "\n",
    "from IPython.core.display import display, HTML, clear_output\n",
    "display(HTML(\"<style>.rendered_html { font-size: 18px; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVqMeWKiU0ay"
   },
   "outputs": [],
   "source": [
    "1 / 0\n",
    "\n",
    "# choose your path here\n",
    "# PROJECT_PATH = '/content/gdrive/My Drive/Colab Notebooks/2019 Autumn - DL/Project'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nNrbrIdMIak"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5R_eU_UMIaq"
   },
   "outputs": [],
   "source": [
    "project_path = PROJECT_PATH\n",
    "\n",
    "import os\n",
    "print(os.listdir(project_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfiC9AvTMIaw"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(project_path, 'modules'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToF9yyNWsiBb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yM5mAuIMIa0"
   },
   "outputs": [],
   "source": [
    "\n",
    "from model import *\n",
    "from load_data import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VzOprpgfOjT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQnujnH9BjVy"
   },
   "source": [
    "### Training utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwamw2TbhqVL"
   },
   "outputs": [],
   "source": [
    "! pip3 install sacrebleu\n",
    "from sacrebleu import corpus_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wqxLnDWJG8I"
   },
   "outputs": [],
   "source": [
    "def calc_loss(criterion, pred, target, pad_idx=0):\n",
    "    target = target[:, 1:]\n",
    "\n",
    "    batch_size, seq_len = target.size()\n",
    "    pred = pred.contiguous().view(batch_size * seq_len, pred.size(-1))\n",
    "    target = target.contiguous().view(batch_size * seq_len)\n",
    "\n",
    "    loss = criterion(ignore_index=pad_idx)(pred, target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_accuracy(pred, target):\n",
    "    # -> : [batch_size, max_seq_len]\n",
    "\n",
    "    rows, cols = torch.where(pred == END_ID)\n",
    "    mask = torch.zeros_like(pred)\n",
    "    mask[rows, cols] = 1\n",
    "    mask = torch.clamp(mask.cumsum(axis=1), max=1)\n",
    "    mask = torch.roll(mask, 1)\n",
    "    mask[:, 0] = 0\n",
    "\n",
    "    pred *= (1 - mask)\n",
    "\n",
    "    acc = torch.eq(torch.sum(torch.eq(pred, target.int()), axis=1).int(), target.size(1)).float().mean().item()\n",
    "    return acc * 100\n",
    "\n",
    "\n",
    "def unpad_string(s, end_id=3):\n",
    "    pattern = re.compile(' %s ' % end_id)\n",
    "    return re.split(pattern, s,maxsplit=1)[0]\n",
    "\n",
    "\n",
    "def calc_bleu(pred, target, vocab_target):\n",
    "    pred = [unpad_string(' '.join([str(token.item()) for token in sent])) for sent in pred]\n",
    "    target = [[unpad_string(' '.join([str(token.item()) for token in sent])) for sent in target]]\n",
    "    return corpus_bleu(pred, target).score\n",
    "\n",
    "\n",
    "def calc_metric(pred, target, metric_name, vocab_target=None):\n",
    "    pred = torch.argmax(pred, dim=-1)\n",
    "    target = target[:, 1:]\n",
    "    if metric_name == 'accuracy':\n",
    "        return calc_accuracy(pred, target)\n",
    "    if metric_name == 'bleu':\n",
    "        return calc_bleu(pred, target, vocab_target)\n",
    "    raise ValueError(\"Choose either 'accuracy' or 'bleu'\")\n",
    "\n",
    "\n",
    "def trainEpoch(model, data_x, data_y, opt,\n",
    "               criterion, metric_name, shuffle, batch_size, max_iter=None):\n",
    "    model.train()\n",
    "\n",
    "    N = len(data_x)\n",
    "    indices = np.arange(N)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    loss_log, metric_log = [], []\n",
    "    n_batches = math.ceil(N / batch_size)\n",
    "    for i in tnrange(n_batches, desc='train batches:'):\n",
    "        if max_iter is not None and i >= max_iter:\n",
    "            break\n",
    "        idx_i = indices[i * batch_size : (i + 1) * batch_size]\n",
    "        x_i = data_x[idx_i]\n",
    "        y_i = data_y[idx_i]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        z_i, y_i = model(x_i, y_i)\n",
    "\n",
    "        loss = 0\n",
    "        loss = calc_loss(criterion, z_i, y_i)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "        metric_log.append(calc_metric(z_i, y_i, metric_name))\n",
    "\n",
    "    return loss_log, metric_log\n",
    "\n",
    "\n",
    "def test(model, data_x, data_y,\n",
    "         criterion, metric_name, batch_size):\n",
    "    model.eval()\n",
    "\n",
    "    N = len(data_x)\n",
    "    indices = np.arange(N)\n",
    "    loss_sum, metric_sum = 0, 0\n",
    "    n_batches = math.ceil(N / batch_size)\n",
    "    for i in tnrange(n_batches, desc='test batches:'):\n",
    "        idx_i = indices[i * batch_size : (i + 1) * batch_size]\n",
    "        x_i = data_x[idx_i]\n",
    "        y_i = data_y[idx_i]\n",
    "\n",
    "        z_i, y_i = model(x_i, y_i)\n",
    "\n",
    "        loss = 0\n",
    "        loss = calc_loss(criterion, z_i, y_i)\n",
    "        loss = loss.item()\n",
    "        loss_sum += loss\n",
    "        metric_sum += calc_metric(z_i, y_i, metric_name)\n",
    "    return loss_sum / n_batches, metric_sum / n_batches\n",
    "\n",
    "\n",
    "def plot_logs(train_loss_log, dev_loss_log, loss_name,\n",
    "              train_metric_log, dev_metric_log, metric_name,\n",
    "              results_path, model_name):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\n",
    "\n",
    "    ax1.plot(train_loss_log, label='train', zorder=1)\n",
    "    ax1.scatter([x[0] for x in dev_loss_log],\n",
    "                [x[1] for x in dev_loss_log],\n",
    "                marker='.', s=90, c='orange', label='dev', zorder=2)\n",
    "    ax1.set_xlabel('batches')\n",
    "    ax1.set_ylabel(loss_name)\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.grid()\n",
    "    ax1.set_title(model_name)\n",
    "\n",
    "    ax2.plot(train_metric_log, label='train', zorder=1)\n",
    "    ax2.scatter([x[0] for x in dev_metric_log],\n",
    "                [x[1] for x in dev_metric_log],\n",
    "                marker='.', s=90, c='orange', label='dev', zorder=2)\n",
    "    ax2.set_xlabel('batches')\n",
    "    ax2.set_ylabel(metric_name)\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.grid()\n",
    "    ax2.set_title(model_name)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig.savefig(os.path.join(results_path, '%s.png' % model_name))\n",
    "\n",
    "\n",
    "\n",
    "def plot_logs_from_model_params(model_params):\n",
    "    model_name = model_params['model_name']\n",
    "    loss_name = model_params['loss_name']\n",
    "    metric_name = model_params['metric_name']\n",
    "    train_loss_log = model_params['logs'][loss_name]['train']\n",
    "    dev_loss_log = model_params['logs'][loss_name]['dev']\n",
    "    train_metric_log = model_params['logs'][metric_name]['train']\n",
    "    dev_metric_log = model_params['logs'][metric_name]['dev']\n",
    "    results_path = model_params['results_path']\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\n",
    "\n",
    "    ax1.plot(train_loss_log, label='train', zorder=1)\n",
    "    ax1.scatter([x[0] for x in dev_loss_log],\n",
    "                [x[1] for x in dev_loss_log],\n",
    "                marker='.', s=90, c='orange', label='dev', zorder=2)\n",
    "    ax1.set_xlabel('batches')\n",
    "    ax1.set_ylabel(loss_name)\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.grid()\n",
    "    ax1.set_title(model_name)\n",
    "\n",
    "    ax2.plot(train_metric_log, label='train', zorder=1)\n",
    "    ax2.scatter([x[0] for x in dev_metric_log],\n",
    "                [x[1] for x in dev_metric_log],\n",
    "                marker='.', s=90, c='orange', label='dev', zorder=2)\n",
    "    ax2.set_xlabel('batches')\n",
    "    ax2.set_ylabel(metric_name)\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.grid()\n",
    "    ax2.set_title(model_name)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig.savefig(os.path.join(results_path, '%s.png' % model_name))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model_params, n_epochs=1, max_iter=None, batch_size=64, shuffle=True,\n",
    "          save_model_after_each_epoch=False):\n",
    "    model = model_params['model']\n",
    "    model_name = model_params['model_name']\n",
    "    train_x = model_params['data']['from']['train']\n",
    "    train_y = model_params['data']['to']['train']\n",
    "    dev_x = model_params['data']['from']['dev']\n",
    "    dev_y = model_params['data']['to']['dev']\n",
    "    opt = model_params['optimiser']\n",
    "    scheduler = model_params['scheduler']\n",
    "    criterion = model_params['criterion']\n",
    "    loss_name = model_params['loss_name']\n",
    "    metric_name = model_params['metric_name']\n",
    "    results_path = model_params['results_path']\n",
    "\n",
    "    train_loss_log, dev_loss_log = [], []\n",
    "    train_metric_log, dev_metric_log = [], []\n",
    "    for epoch in range(n_epochs):\n",
    "        t = time()\n",
    "\n",
    "        train_loss, train_metric = trainEpoch(model, train_x, train_y, opt, criterion,\n",
    "                                              metric_name, shuffle, batch_size, max_iter)\n",
    "        train_loss_log.extend(train_loss)\n",
    "        train_metric_log.extend(train_metric)\n",
    "\n",
    "        dev_loss, dev_metric = test(model, dev_x, dev_y, criterion,\n",
    "                                    metric_name, batch_size)\n",
    "        dev_loss_log.append((len(train_loss_log) - 1, dev_loss))\n",
    "        dev_metric_log.append((len(train_metric_log) - 1, dev_metric))\n",
    "\n",
    "        print('\\n' + '=' * 130)\n",
    "        print('Epoch %d / %d:' % (epoch + 1, n_epochs), end='\\t')\n",
    "        print('train %s = %.3f, dev %s = %.3f, '\n",
    "              'train %s = %.2f, dev %s = %.2f, %d seconds' %\n",
    "              (loss_name, np.mean(train_loss),\n",
    "               loss_name, dev_loss,\n",
    "               metric_name,  np.mean(train_metric),\n",
    "               metric_name, dev_metric, int(time() - t)))\n",
    "        scheduler.step(dev_loss)\n",
    "        print('=' * 130 + '\\n')\n",
    "        \n",
    "        if save_model_after_each_epoch:\n",
    "            save_model_to(model, results_path, 'model %s epoch %d.pth' %\n",
    "                          (model_name, epoch + 1))  \n",
    "\n",
    "    plot_logs(train_loss_log, dev_loss_log, loss_name,\n",
    "              train_metric_log, dev_metric_log, metric_name,\n",
    "              results_path, model_name)\n",
    "\n",
    "    return {\n",
    "        loss_name : {'train' : train_loss_log, 'dev' : dev_loss_log},\n",
    "        metric_name : {'train' : train_metric_log, 'dev' : dev_metric_log}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWmf5pRRV87c"
   },
   "outputs": [],
   "source": [
    "def save_model_to(model, folder_path, file_name):\n",
    "    with open(os.path.join(folder_path, file_name), 'wb') as f:\n",
    "        torch.save(model.state_dict(), f)\n",
    "\n",
    "def load_model_from(model, folder_path, file_name):\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_object_to(obj, folder_path, file_name):\n",
    "    with open(os.path.join(folder_path, file_name), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object_from(folder_path, file_name):\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1327w0H61n9R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njf7yCaKWIHC"
   },
   "source": [
    "### Get needed model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHznXVxbWP0w"
   },
   "outputs": [],
   "source": [
    "def get_model(task, alpha_attn, alpha_output, project_path,\n",
    "              setting=None, L1=None, L2=None, LR=1e-3):\n",
    "    '''\n",
    "    task : {'mt' or 'inflection'}\n",
    "\n",
    "    setting : {'high' or 'medium'}\n",
    "    \n",
    "    {L1, L2} = {'en', 'de'}\n",
    "    ____\n",
    "    Output: dict of following keys { model, model_name, vocab, data, results_path, \\\n",
    "            direction_to_lang, optimiser, scheduler, criterion, loss_name, metric_name }\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path = os.path.join(project_path, 'data')\n",
    "    results_path = os.path.join(project_path, 'results')\n",
    "\n",
    "    vocab = dict()\n",
    "    data = dict()\n",
    "    direction_to_lang = None\n",
    "\n",
    "    model_name = '%s' % task\n",
    "\n",
    "    embed_size = None\n",
    "    hidden_size = None\n",
    "\n",
    "    if task == 'mt':\n",
    "\n",
    "        embed_size = 500\n",
    "        hidden_size = 500\n",
    "\n",
    "        data_path = os.path.join(data_path, 'translation')\n",
    "        results_path = os.path.join(results_path, 'translation')\n",
    "\n",
    "        if not ((L1 == 'en' and L2 == 'de') or\n",
    "                (L1 == 'de' and L2 == 'en')):\n",
    "            raise ValueError('Specify languages correctly')\n",
    "\n",
    "        model_name += ' %s -> %s' % (L1, L2)\n",
    "        direction_to_lang = { 'from' : L1, 'to' : L2 }\n",
    "        lang_to_dir = { L1 : 'from', L2 : 'to'}\n",
    "        for lang in [L1, L2]:\n",
    "            vocab[lang_to_dir[lang]] = make_vocabulary_mt(\n",
    "                os.path.join(data_path, 'vocab.%s' % lang), lang\n",
    "            )\n",
    "            data[lang_to_dir[lang]] = dict()\n",
    "            for set_type in ['train', 'dev', 'test']:\n",
    "                data[lang_to_dir[lang]][set_type] = load_data_file(data_path,\n",
    "                    '%s.BPE.%s' % (set_type, lang))\n",
    "                if lang == L2:\n",
    "                    # add SOS, EOS for training and evaluation\n",
    "                    data[lang_to_dir[L2]][set_type] = np.array([\n",
    "                        [BEGIN_TOKEN] + x + [END_TOKEN] for x in data[lang_to_dir[L2]][set_type]\n",
    "                    ])\n",
    "\n",
    "    elif task == 'inflection':\n",
    "\n",
    "        embed_size = 300\n",
    "        hidden_size = 300\n",
    "\n",
    "        data_path = os.path.join(data_path, 'inflection')\n",
    "        results_path = os.path.join(results_path, 'inflection')\n",
    "\n",
    "        if setting not in {'medium', 'high'}:\n",
    "            raise ValueError('Specify setting correctly')\n",
    "        \n",
    "        model_name += ' %s' % setting\n",
    "        data_path = os.path.join(data_path, setting)\n",
    "        results_path = os.path.join(results_path, setting)\n",
    "\n",
    "        direction_to_xy = { 'from' : 'x', 'to' : 'y'}\n",
    "        for direction in ['from', 'to']:\n",
    "            data[direction] = dict()\n",
    "            for set_type in ['train', 'dev', 'test']:\n",
    "                data[direction][set_type] = load_data_file(data_path,\n",
    "                    '%s_%s' % (set_type, direction_to_xy[direction]))\n",
    "            vocab[direction] = make_vocabulary_inflection(data[direction]['train'], direction,\n",
    "                                                          setting + ' ' + direction)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Specify task correctly')\n",
    "\n",
    "\n",
    "    criterion, loss_name = None, None\n",
    "    if alpha_output == 1.0:\n",
    "        criterion = nn.CrossEntropyLoss\n",
    "        loss_name = 'cross entropy'\n",
    "    elif alpha_output == 1.5:\n",
    "        criterion = Entmax15Loss\n",
    "        loss_name = '1.5-entmax loss'\n",
    "    elif alpha_output == 2.0:\n",
    "        criterion = SparsemaxLoss\n",
    "        loss_name = '2-entmax loss'\n",
    "    else:\n",
    "        raise NotImplementedError('Select alpha from {1.0, 1.5, 2.0}')\n",
    "    model_name += ' alpha_attn %s alpha_out %s' % (str(alpha_attn), str(alpha_output))\n",
    "\n",
    "\n",
    "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Seq2Seq(vocab['from'], vocab['to'], embed_size, hidden_size, DEVICE,\n",
    "                    alpha_attn)\n",
    "    model = model.to(DEVICE)\n",
    "    print('Model name: %s' % model_name)\n",
    "    print('DEVICE:', DEVICE)\n",
    "\n",
    "    n_params_grad = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    n_params_no_grad = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    print('Parameters requiring grad: %d, other parameters: %d' % (n_params_grad, n_params_no_grad))\n",
    "\n",
    "    optimiser = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimiser, factor=0.5, patience=0, verbose=True)\n",
    "\n",
    "\n",
    "    metric_name = 'bleu' if task == 'mt' else 'accuracy'\n",
    "\n",
    "    print('Loss: %s\\nMetric: %s' % (loss_name, metric_name))\n",
    "\n",
    "\n",
    "    return {\n",
    "        'model' : model,\n",
    "        'model_name' : model_name,\n",
    "        'vocab' : vocab,\n",
    "        'data' : data,\n",
    "        'results_path' : results_path,\n",
    "        'dir_to_lang' : direction_to_lang,\n",
    "        'optimiser' : optimiser,\n",
    "        'scheduler' : scheduler,\n",
    "        'criterion' : criterion,\n",
    "        'loss_name' : loss_name,\n",
    "        'metric_name' : metric_name,\n",
    "        'logs' : dict()\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAVdS37h_cA_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dzCIqOtWsc6"
   },
   "source": [
    "### Create model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iAf93n6TKXnY"
   },
   "outputs": [],
   "source": [
    "# choose your model parameter:\n",
    "TASK = 'inflection' # 'mt' or 'inflection'\n",
    "ALPHA_ATTENTION = 1.0\n",
    "ALPHA_LOSS = 1.0\n",
    "INFLECTION_SETTING = 'medium' # 'medium' or 'high', None by default\n",
    "MT_L1 = 'de' # source language: 'en' or 'de', None by default\n",
    "MT_L2 = 'en' # target language: 'de' or 'en', None by default\n",
    "SAVE_MODEL_AFTER_EPOCH = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2LS-rC7ibRU"
   },
   "outputs": [],
   "source": [
    "model_params = get_model(TASK,\n",
    "                         alpha_attn=ALPHA_ATTENTION, ALPHA_LOSS=2.0,\n",
    "                         project_path=PROJECT_PATH,\n",
    "                         setting=INFLECTION_SETTING,\n",
    "                         L1=MT_L1, L2=MT_L2,\n",
    "                         save_model_after_each_epoch=SAVE_MODEL_AFTER_EPOCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skgob3SuW0at"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nL1W8ghEW0yJ"
   },
   "source": [
    "### Load model weights or logs if needed (you need to create it first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBA2YFr2XAJn"
   },
   "outputs": [],
   "source": [
    "# We could not store the weights of our models on GitHub\n",
    "\n",
    "'''\n",
    "load_model_from(model_params['model'],\n",
    "                model_params['results_path'],\n",
    "                'model %s.pth' % model_params['model_name'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3zuereEXAJy"
   },
   "outputs": [],
   "source": [
    "# training and validation logs:\n",
    "\n",
    "# model_params['logs'] = load_object_from(model_params['results_path'], 'logs %s.pkl' % model_params['model_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q98mMExiWyXh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqxcaO4TXBfU"
   },
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBoYD6Q0pC6k"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 1\n",
    "MAX_ITER = None\n",
    "USE_SHUFFLE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxhwi3h5o8MP"
   },
   "outputs": [],
   "source": [
    "model_params['logs'] = train(model_params,\n",
    "                             n_epochs=N_EPOCHS, max_iter=MAX_ITER, batch_size=BATCH_SIZE, shuffle=USE_SHUFFLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN-uqzIwfCVq"
   },
   "outputs": [],
   "source": [
    "model_params['model'].eval()\n",
    "\n",
    "test(model_params['model'],\n",
    "     model_params['data']['from']['test'],\n",
    "     model_params['data']['to']['test'],\n",
    "     model_params['criterion'], model_params['metric_name'], BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XeoXtB7Rv5Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kuHo038nI5I"
   },
   "source": [
    "### Save results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfQCuW9OWScD"
   },
   "outputs": [],
   "source": [
    "save_model_to(model_params['model'], model_params['results_path'], 'model %s.pth' % model_params['model_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPkvAkGIIR4q"
   },
   "outputs": [],
   "source": [
    "save_object_to(model_params['logs'], model_params['results_path'], 'logs %s.pkl' % model_params['model_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t45Wpr6cIR9E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FQnujnH9BjVy",
    "njf7yCaKWIHC",
    "2dzCIqOtWsc6",
    "nL1W8ghEW0yJ",
    "YqxcaO4TXBfU",
    "6kuHo038nI5I"
   ],
   "name": "train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
